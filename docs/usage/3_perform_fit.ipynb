{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Perform fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the [previous step](2_generate_data), an [IntensityTF](tensorwaves.physics.helicity_formalism.amplitude.IntensityTF) object behaves just like a mathematical function that takes a set of data points as an argument and returns a list of intensities (real numbers). At this stage, we want to optimize the parameters of the intensity model, so that it matches the distribution of our data sample. This is what we call 'performing a fit'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "We first load the relevant data from the previous steps.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from expertsystem import io\n",
    "\n",
    "from tensorwaves.physics.helicity_formalism.amplitude import IntensityBuilder\n",
    "from tensorwaves.physics.helicity_formalism.kinematics import HelicityKinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = io.load_amplitude_model(\"amplitude_model_helicity.yml\")\n",
    "kinematics = HelicityKinematics.from_model(model)\n",
    "data_sample = np.load(\"data_sample.npy\")\n",
    "phsp_sample = np.load(\"phsp_sample.npy\")\n",
    "intensity_builder = IntensityBuilder(model.particles, kinematics, phsp_sample)\n",
    "intensity = intensity_builder.create_intensity(model)\n",
    "phsp_set = kinematics.convert(phsp_sample)\n",
    "data_set = kinematics.convert(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Define estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a fit, you need to define an **estimator**. An estimator is a measure for the discrepancy between the intensity model and the data distribution to which you fit. In PWA, we usually use an *unbinned negative log likelihood estimator*, which can be created as follows with the [tensorwaves.estimator](tensorwaves.estimator) module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorwaves.estimator import UnbinnedNLL\n",
    "\n",
    "estimator = UnbinnedNLL(intensity, data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters that the [UnbinnedNLL](tensorwaves.estimator.UnbinnedNLL) carries, have been taken from the [IntensityTF](tensorwaves.physics.helicity_formalism.amplitude.IntensityTF) object and you'll recognize them from the YAML recipe file that we created in [Step 1](1_create_model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Optimize the intensity model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to perform the fit! This is the part where the TensorFlow backend comes into play. For this reason, we suppress a few warnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the fit itself is quite simple: just create an optimizer instance of your choice, here [Minuit2](https://root.cern.ch/doc/master/Minuit2Page.html), and call its [optimize](tensorwaves.optimizer.minuit.Minuit2.optimize) method to start the fitting process. Notice that the [optimize](tensorwaves.optimizer.minuit.Minuit2.optimize) method requires a second argument. This is a mapping of parameter names that you want to fit to their initial values.\n",
    "\n",
    "Let's first select a few of the parameters that we saw in {ref}`Step 3.1 <usage/3_perform_fit:3.1 Define estimator>` and feed them to the optimizer to run the fit. Notice that we modify the parameters slightly to make the fit more interesting (we are running using a data sample that was generated with this very amplitude model after all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_parameters = {\n",
    "    \"Phase_J/psi(1S)_to_f(0)(1500)_0+gamma_1;f(0)(1500)_to_pi0_0+pi0_0;\": 0.0,\n",
    "    \"Width_f(0)(500)\": 0.12,\n",
    "    \"Position_f(0)(1710)\": 1.8,\n",
    "    \"Width_f(0)(1710)\": 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that an [IntensityTF](tensorwaves.physics.helicity_formalism.amplitude.IntensityTF) object is really just a [Function](tensorwaves.interfaces.Function) that computes the intensity for a certain dataset. This can be seen now nicely when we use these intensities as weights on the phase space sample and plot it together with the original dataset. Here, we look at the invariant mass distribution projection of the final states `3` and `4`, which, {ref}`as we saw before <usage/2_generate_data:2.4 Visualize kinematic variables>`, are the final state particles $\\pi^0,\\pi^0$.\n",
    "\n",
    "Don't forget to use [update_parameters](tensorwaves.physics.helicity_formalism.amplitude.IntensityTF.update_parameters) first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compare_model(\n",
    "    variable_name, data_set, phsp_set, intensity_model, transform=lambda p: p, bins=100\n",
    "):\n",
    "    data = transform(data_set[variable_name])\n",
    "    phsp = transform(phsp_set[variable_name])\n",
    "    intensities = intensity_model(phsp_set)\n",
    "    plt.hist(data, bins=bins, alpha=0.5, label=\"data\", density=True)\n",
    "    plt.hist(\n",
    "        phsp,\n",
    "        weights=intensities,\n",
    "        bins=bins,\n",
    "        histtype=\"step\",\n",
    "        color=\"red\",\n",
    "        label=\"initial fit model\",\n",
    "        density=True,\n",
    "    )\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity.update_parameters(initial_parameters)\n",
    "compare_model(\"mSq_3+4\", data_set, phsp_set, intensity, np.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create an [Optimizer](tensorwaves.interfaces.Optimizer) to [optimize](tensorwaves.optimizer.minuit.Minuit2.optimize) the model (which is embedded in the [Estimator](tensorwaves.interfaces.Estimator). Only the parameters that are given to the [optimize](tensorwaves.optimizer.minuit.Minuit2.optimize) method are optimized.\n",
    "\n",
    "Here, we choose to use {class}`.Minuit2`, which is the most common optimizer choice in high-energy physics. Notice that the {class}`.Minuit2` class allows one to list {mod}`~tensorwaves.optimizer.callbacks`. These are called during the {meth}`~.Optimizer.optimize` method. Here, we use {class}`.CallbackList` to 'stack' several callbacks together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{toggle}\n",
    "To define your own callback, create a class that inherits from the {class}`~.Callback` class and feed it to the {class}`.Minuit2` constructor.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorwaves.optimizer.callbacks import (\n",
    "    CallbackList,\n",
    "    CSVSummary,\n",
    "    TFSummary,\n",
    "    YAMLSummary,\n",
    ")\n",
    "from tensorwaves.optimizer.minuit import Minuit2\n",
    "\n",
    "minuit2 = Minuit2(\n",
    "    callback=CallbackList(\n",
    "        [\n",
    "            TFSummary(),\n",
    "            YAMLSummary(\"current_fit_result.yaml\"),\n",
    "            CSVSummary(\"fit_traceback.csv\", step_size=2),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "result = minuit2.optimize(estimator, initial_parameters)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Computation time â€• around a minute in this case\n",
    "---\n",
    "class: dropdown\n",
    "---\n",
    "The computation time depends on the complexity of the model, number of data events, the size of the phase space sample, and the number of free parameters. This model is rather small and has but a few free parameters, so the optimization shouldn't take more than a few minutes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the values of the optimized parameters in the result are again comparable to the original values we saw in {ref}`usage/3_perform_fit:3.1 Define estimator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_parameters = result[\"parameter_values\"]\n",
    "optimized_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Export and import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In {ref}`usage/3_perform_fit:3.2 Optimize the intensity model`, we initialized {obj}`.Minuit2` with some callbacks that are {class}`.Loadable`. Such callback classes offer the possibility to {meth}`.Loadable.load_latest_parameters`, so you can pick up the optimize process in case it crashes or if you pause it. Loading the latest parameters goes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_parameters = YAMLSummary.load_latest_parameters(\"current_fit_result.yaml\")\n",
    "latest_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restart the fit with the latest parameters, simply rerun as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit2 = Minuit2()\n",
    "minuit2.optimize(estimator, latest_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo and behold: the parameters were already optimized, so the fit converged faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot optimized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same method as above, we renew the parameters of the [IntensityTF](tensorwaves.physics.helicity_formalism.amplitude.IntensityTF) and plot it again over the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity.update_parameters(latest_parameters)\n",
    "compare_model(\"mSq_3+4\", data_set, phsp_set, intensity, np.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze optimization process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that {ref}`in Step 3.2 <usage/3_perform_fit:3.2 Optimize the intensity model>`, we initialized {class}`.Minuit2` with a {class}`.TFSummary` callback as well. Its output files provide a nice, interactive representation of the fit process and can be viewed with [TensorBoard](https://www.tensorflow.org/tensorboard/get_started) as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{tabbed} Terminal\n",
    "```bash\n",
    "tensorboard --logdir logs\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabbed} Python\n",
    "```python\n",
    "import tensorboard as tb\n",
    "\n",
    "tb.notebook.list()  # View open TensorBoard instances\n",
    "tb.notebook.start(args_string=\"--logdir logs\")\n",
    "```\n",
    "See more info [here](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks#tensorboard_in_notebooks)\n",
    "````\n",
    "\n",
    "````{tabbed} Jupyter notebook\n",
    "```ipython\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n",
    "```\n",
    "See more info [here](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks#tensorboard_in_notebooks)\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative would be to use the output of the {class}`.CSVSummary` callback. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fit_traceback = pd.read_csv(\"fit_traceback.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_traceback.plot(\"function_call\", \"estimator_value\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_traceback.plot(\n",
    "    \"function_call\",\n",
    "    [\n",
    "        \"Phase_J/psi(1S)_to_f(0)(1500)_0+gamma_1;f(0)(1500)_to_pi0_0+pi0_0;\",\n",
    "        \"Position_f(0)(1710)\",\n",
    "        \"Width_f(0)(1710)\",\n",
    "    ],\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
