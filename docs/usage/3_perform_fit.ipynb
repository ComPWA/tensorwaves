{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Perform fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the [previous step](2_generate_data), an [IntensityTF](tensorwaves.physics.helicity_formalism.amplitude.IntensityTF) object behaves just like a mathematical function that takes a set of data points as an argument and returns a list of intensities (real numbers). At this stage, we want to optimize the parameters of the intensity model, so that it matches the distribution of our data sample. This is what we call 'performing a fit'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```{note}\n",
    "We first load the relevant data from the previous steps.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from expertsystem import io\n",
    "\n",
    "from tensorwaves.physics.helicity_formalism.amplitude import IntensityBuilder\n",
    "from tensorwaves.physics.helicity_formalism.kinematics import HelicityKinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = io.load_amplitude_model(\"amplitude_model_helicity.yml\")\n",
    "kinematics = HelicityKinematics.from_model(model)\n",
    "data_sample = np.load(\"data_sample.npy\")\n",
    "phsp_sample = np.load(\"phsp_sample.npy\")\n",
    "intensity_builder = IntensityBuilder(model.particles, kinematics, phsp_sample)\n",
    "intensity = intensity_builder.create_intensity(model)\n",
    "phsp_set = kinematics.convert(phsp_sample)\n",
    "data_set = kinematics.convert(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Define estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a fit, you need to define an **estimator**. An estimator is a measure for the discrepancy between the intensity model and the data distribution to which you fit. In PWA, we usually use an *unbinned negative log likelihood estimator*, which can be created as follows with the [tensorwaves.estimator](tensorwaves.estimator) module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorwaves.estimator import UnbinnedNLL\n",
    "\n",
    "estimator = UnbinnedNLL(intensity, data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters that the [UnbinnedNLL](tensorwaves.estimator.UnbinnedNLL) carries, have been taken from the [IntensityTF](tensorwaves.physics.helicity_formalism.amplitude.IntensityTF) object and you'll recognize them from the YAML recipe file that we created in [Step 1](1_create_model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Optimize the intensity model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to perform the fit! This is the part where the TensorFlow backend comes into play. For this reason, we suppress a few warnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the fit itself is quite simple: just create an optimizer instance of your choice, here [Minuit2](https://root.cern.ch/doc/master/Minuit2Page.html), and call its [optimize](tensorwaves.optimizer.minuit.Minuit2.optimize) method to start the fitting process. Notice that the [optimize](tensorwaves.optimizer.minuit.Minuit2.optimize) method requires a second argument. This is a mapping of parameter names that you want to fit to their initial values.\n",
    "\n",
    "Let's first select a few of the parameters that we saw in [Step 3.1](#3.1-Define-estimator) and feed them to the optimizer to run the fit. Notice that we modify the parameters slightly to make the fit more interesting (we are running using a data sample that was generated with this very amplitude model after all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_parameters = {\n",
    "    \"Phase_J/psi(1S)_to_f(0)(1500)_0+gamma_1;f(0)(1500)_to_pi0_0+pi0_0;\": 0.0,\n",
    "    \"Width_f(0)(500)\": 0.1,\n",
    "    \"Mass_f(0)(980)\": 0.9,\n",
    "    \"Mass_f(0)(1500)\": 1.55,\n",
    "    \"Mass_f(0)(1710)\": 1.8,\n",
    "    \"Width_f(0)(1710)\": 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that an [IntensityTF](tensorwaves.physics.helicity_formalism.amplitude.IntensityTF) object is really just a [Function](tensorwaves.interfaces.Function) that computes the intensity for a certain dataset. This can be seen now nicely when we use these intensities as weights on the phase space sample and plot it together with the original dataset. Here, we look at the invariant mass distribution projection of the final states `3` and `4`, which, {ref}`as we saw before <usage/2_generate_data:2.4 Visualize kinematic variables>`, are the final state particles $\\pi^0,\\pi^0$.\n",
    "\n",
    "Don't forget to use [update_parameters](tensorwaves.physics.helicity_formalism.amplitude.IntensityTF.update_parameters) first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compare_model(\n",
    "    variable_name, data_set, phsp_set, intensity_model, transform=lambda p: p, bins=100\n",
    "):\n",
    "    data = transform(data_set[variable_name])\n",
    "    phsp = transform(phsp_set[variable_name])\n",
    "    intensities = intensity_model(phsp_set)\n",
    "    plt.hist(data, bins=bins, alpha=0.5, label=\"data\", density=True)\n",
    "    plt.hist(\n",
    "        phsp,\n",
    "        weights=intensities,\n",
    "        bins=bins,\n",
    "        histtype=\"step\",\n",
    "        color=\"red\",\n",
    "        label=\"initial fit model\",\n",
    "        density=True,\n",
    "    )\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity.update_parameters(initial_parameters)\n",
    "compare_model(\"mSq_3_4\", data_set, phsp_set, intensity, np.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create an [Optimizer](tensorwaves.interfaces.Optimizer) to [optimize](tensorwaves.optimizer.minuit.Minuit2.optimize) the model (which is embedded in the [Estimator](tensorwaves.interfaces.Estimator). Only the parameters that are given to the [optimize](tensorwaves.optimizer.minuit.Minuit2.optimize) method are optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorwaves.optimizer.minuit import Minuit2\n",
    "\n",
    "minuit2 = Minuit2()\n",
    "result = minuit2.optimize(estimator, initial_parameters)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```{admonition} Computation time â€• around a minute in this case\n",
    "---\n",
    "class: dropdown\n",
    "---\n",
    "The computation time depends on the complexity of the model, number of data events, the size of the phase space sample, and the number of free parameters. This model is rather small and has but a few free parameters, so the optimization shouldn't take more than a few minutes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same method as above, we renew the parameters of the [IntensityTF](tensorwaves.physics.helicity_formalism.amplitude.IntensityTF) and plot it again over the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity.update_parameters(initial_parameters)\n",
    "compare_model(\"mSq_3_4\", data_set, phsp_set, intensity, np.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Export fit result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```{admonition} Not implemented yet\n",
    "---\n",
    "class: dropdown\n",
    "---\n",
    "This functionality has not yet been implemented. See [issue 99](https://github.com/ComPWA/tensorwaves/issues/99).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing an intensity model can take a long time, so it is important that you store the fit result in the end. We can simply [dump](json.dump) the file to [json](json):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"tensorwaves_fit_result.json\", \"w\") as stream:\n",
    "    json.dump(result, stream, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and [load](json.load) it back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tensorwaves_fit_result.json\") as stream:\n",
    "    result = json.load(stream)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
